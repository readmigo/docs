# CI/CD é…ç½®æ–‡ä»¶è¯¦ç»†è®¡åˆ’

## 1. é›¶åœæœºéƒ¨ç½²åˆ†æ

### 1.1 éƒ¨ç½²æœŸé—´æœåŠ¡å¯ç”¨æ€§é—®é¢˜

**é—®é¢˜**ï¼šéƒ¨ç½²æ—¶æ˜¯å¦ä¼šå¯¼è‡´çº¿ä¸Šç”¨æˆ·æ— æ³•æ­£å¸¸è®¿é—®æœåŠ¡ï¼Ÿ

**ç­”æ¡ˆ**ï¼šä½¿ç”¨æ­£ç¡®é…ç½®åï¼Œ**ä¸ä¼š**å¯¼è‡´æœåŠ¡ä¸­æ–­ã€‚

### 1.2 Fly.io é›¶åœæœºéƒ¨ç½²æœºåˆ¶

```mermaid
graph TD
    subgraph phase1["é˜¶æ®µ 1: éƒ¨ç½²æ–°ç‰ˆæœ¬"]
        LB1["Load Balancer"] -->|100% æµé‡| V1_1["æ—§å®ä¾‹ (v1)"]
        LB1 -.->|å¯åŠ¨ä¸­...| V2_1["æ–°å®ä¾‹ (v2)"]
    end
    subgraph phase2["é˜¶æ®µ 2: å¥åº·æ£€æŸ¥é€šè¿‡"]
        LB2["Load Balancer"] -->|50% æµé‡| V1_2["æ—§å®ä¾‹ (v1)"]
        LB2 -->|50% æµé‡| V2_2["æ–°å®ä¾‹ (v2)<br>Health Check Passed"]
    end
    subgraph phase3["é˜¶æ®µ 3: åˆ‡æ¢å®Œæˆ"]
        V1_3["æ—§å®ä¾‹ (v1) - åœæ­¢"] -.- X["X"]
        LB3["Load Balancer"] -->|100% æµé‡| V2_3["æ–°å®ä¾‹ (v2)"]
    end
    phase1 --> phase2 --> phase3
```

> å…³é”®é…ç½®:
> - min_machines_running = 1 (å§‹ç»ˆä¿æŒè‡³å°‘1ä¸ªå®ä¾‹è¿è¡Œ)
> - grace_period = "15s" (æ–°å®ä¾‹å¯åŠ¨åçš„ç­‰å¾…æ—¶é—´)
> - health check å¿…é¡»é€šè¿‡æ‰åˆ‡æ¢æµé‡

### 1.3 æ•°æ®åº“è¿ç§»çš„é›¶åœæœºç­–ç•¥

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        æ•°æ®åº“è¿ç§»é›¶åœæœºç­–ç•¥                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                  â”‚
â”‚   âš ï¸  é£é™©åœºæ™¯:                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚  1. åˆ é™¤å­—æ®µ/è¡¨ - æ—§ä»£ç å¯èƒ½è¿˜åœ¨ä½¿ç”¨                                      â”‚    â”‚
â”‚   â”‚  2. é‡å‘½åå­—æ®µ - æ–°æ—§ä»£ç ä¸å…¼å®¹                                           â”‚    â”‚
â”‚   â”‚  3. ä¿®æ”¹å­—æ®µç±»å‹ - å¯èƒ½å¯¼è‡´æ•°æ®ä¸¢å¤±                                       â”‚    â”‚
â”‚   â”‚  4. æ·»åŠ éç©ºå­—æ®µ - æ—§æ•°æ®æ²¡æœ‰é»˜è®¤å€¼                                       â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                                  â”‚
â”‚   âœ… å®‰å…¨è¿ç§»æ¨¡å¼:                                                               â”‚
â”‚                                                                                  â”‚
â”‚   æ·»åŠ å­—æ®µ (å®‰å…¨):                                                               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚  1. æ·»åŠ å¯ç©ºå­—æ®µæˆ–å¸¦é»˜è®¤å€¼çš„å­—æ®µ                                          â”‚    â”‚
â”‚   â”‚  2. éƒ¨ç½²æ–°ä»£ç                                                            â”‚    â”‚
â”‚   â”‚  3. å¡«å……æ•°æ® (å¦‚éœ€è¦)                                                    â”‚    â”‚
â”‚   â”‚  4. è®¾ç½®éç©ºçº¦æŸ (ä¸‹ä¸ªç‰ˆæœ¬)                                               â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                                  â”‚
â”‚   åˆ é™¤å­—æ®µ (ä¸¤æ­¥):                                                               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚  ç‰ˆæœ¬ N:   ä»£ç åœæ­¢ä½¿ç”¨è¯¥å­—æ®µ                                             â”‚    â”‚
â”‚   â”‚  ç‰ˆæœ¬ N+1: è¿ç§»è„šæœ¬åˆ é™¤å­—æ®µ                                               â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                                  â”‚
â”‚   é‡å‘½åå­—æ®µ (ä¸‰æ­¥):                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚  ç‰ˆæœ¬ N:   æ·»åŠ æ–°å­—æ®µï¼Œä»£ç åŒæ—¶å†™å…¥æ–°æ—§å­—æ®µ                                â”‚    â”‚
â”‚   â”‚  ç‰ˆæœ¬ N+1: è¿ç§»æ•°æ®ï¼Œä»£ç åªè¯»å†™æ–°å­—æ®µ                                     â”‚    â”‚
â”‚   â”‚  ç‰ˆæœ¬ N+2: åˆ é™¤æ—§å­—æ®µ                                                    â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.4 éƒ¨ç½²ç­–ç•¥é…ç½®

```toml
# fly.toml ä¸­çš„å…³é”®é…ç½®

[deploy]
  strategy = "rolling"      # æ»šåŠ¨éƒ¨ç½² (é»˜è®¤)
  # strategy = "bluegreen"  # è“ç»¿éƒ¨ç½² (å¯é€‰ï¼Œæ›´å®‰å…¨ä½†éœ€è¦æ›´å¤šèµ„æº)
  # strategy = "canary"     # é‡‘ä¸é›€å‘å¸ƒ (å¯é€‰)

[http_service]
  min_machines_running = 1  # å§‹ç»ˆä¿æŒè‡³å°‘1ä¸ªå®ä¾‹
  auto_stop_machines = true
  auto_start_machines = true

# å¥åº·æ£€æŸ¥ - ç¡®ä¿æ–°å®ä¾‹å¥åº·åæ‰æ¥æ”¶æµé‡
[[services.http_checks]]
  interval = "10s"
  timeout = "5s"
  grace_period = "15s"    # å¯åŠ¨åç­‰å¾…æ—¶é—´
  method = "GET"
  path = "/api/v1/health"
```

---

## 2. é…ç½®æ–‡ä»¶è¯¦ç»†å†…å®¹

### 2.1 Fly.io é…ç½®æ–‡ä»¶

#### fly.debugging.toml

```toml
# Fly.io Configuration for Readmigo Debugging Environment
app = "readmigo-debug"
primary_region = "nrt"

[build]
  dockerfile = "Dockerfile"

[deploy]
  strategy = "rolling"

[env]
  NODE_ENV = "development"
  ENVIRONMENT = "debugging"
  PORT = "8080"
  LOG_LEVEL = "debug"
  SENTRY_ENVIRONMENT = "debugging"
  DEBUG_MODE_ENABLED = "true"
  DEFAULT_CHINESE_CONTENT = "true"

[http_service]
  internal_port = 8080
  force_https = true
  auto_stop_machines = true
  auto_start_machines = true
  min_machines_running = 0  # å¯ä»¥å®Œå…¨åœæ­¢ä»¥èŠ‚çœæˆæœ¬
  processes = ["app"]

  [http_service.concurrency]
    type = "requests"
    hard_limit = 100
    soft_limit = 80

[[vm]]
  cpu_kind = "shared"
  cpus = 1
  memory_mb = 512

[[services]]
  protocol = "tcp"
  internal_port = 8080

  [[services.ports]]
    port = 80
    handlers = ["http"]
    force_https = true

  [[services.ports]]
    port = 443
    handlers = ["tls", "http"]

  [[services.http_checks]]
    interval = "30s"
    timeout = "5s"
    grace_period = "15s"
    method = "GET"
    path = "/api/v1/health"
```

#### fly.staging.toml

```toml
# Fly.io Configuration for Readmigo Staging Environment
app = "readmigo-staging"
primary_region = "nrt"

[build]
  dockerfile = "Dockerfile"

[deploy]
  strategy = "rolling"

[env]
  NODE_ENV = "production"
  ENVIRONMENT = "staging"
  PORT = "8080"
  LOG_LEVEL = "info"
  SENTRY_ENVIRONMENT = "staging"
  DEBUG_MODE_ENABLED = "false"
  DEFAULT_CHINESE_CONTENT = "false"

[http_service]
  internal_port = 8080
  force_https = true
  auto_stop_machines = true
  auto_start_machines = true
  min_machines_running = 1  # å§‹ç»ˆä¿æŒ1ä¸ªå®ä¾‹
  processes = ["app"]

  [http_service.concurrency]
    type = "requests"
    hard_limit = 200
    soft_limit = 150

[[vm]]
  cpu_kind = "shared"
  cpus = 1
  memory_mb = 1024

[[services]]
  protocol = "tcp"
  internal_port = 8080

  [[services.ports]]
    port = 80
    handlers = ["http"]
    force_https = true

  [[services.ports]]
    port = 443
    handlers = ["tls", "http"]

  [[services.tcp_checks]]
    interval = "15s"
    timeout = "2s"
    grace_period = "10s"

  [[services.http_checks]]
    interval = "15s"
    timeout = "5s"
    grace_period = "15s"
    method = "GET"
    path = "/api/v1/health"
```

#### fly.production.toml (åŸºäºç°æœ‰ fly.toml å¢å¼º)

```toml
# Fly.io Configuration for Readmigo Production Environment
app = "readmigo-api"
primary_region = "nrt"

[build]
  dockerfile = "Dockerfile"

[deploy]
  strategy = "rolling"
  # ç”Ÿäº§ç¯å¢ƒå¯è€ƒè™‘ä½¿ç”¨ bluegreen æ›´å®‰å…¨
  # strategy = "bluegreen"

[env]
  NODE_ENV = "production"
  ENVIRONMENT = "production"
  PORT = "8080"
  LOG_LEVEL = "warn"
  SENTRY_ENVIRONMENT = "production"

[http_service]
  internal_port = 8080
  force_https = true
  auto_stop_machines = true
  auto_start_machines = true
  min_machines_running = 1  # ç”Ÿäº§ç¯å¢ƒå§‹ç»ˆä¿æŒè¿è¡Œ
  processes = ["app"]

  [http_service.concurrency]
    type = "requests"
    hard_limit = 250
    soft_limit = 200

[[vm]]
  cpu_kind = "shared"
  cpus = 1
  memory_mb = 512

[[services]]
  protocol = "tcp"
  internal_port = 8080

  [[services.ports]]
    port = 80
    handlers = ["http"]
    force_https = true

  [[services.ports]]
    port = 443
    handlers = ["tls", "http"]

  [[services.tcp_checks]]
    interval = "15s"
    timeout = "2s"
    grace_period = "10s"

  [[services.http_checks]]
    interval = "30s"
    timeout = "5s"
    grace_period = "15s"
    method = "GET"
    path = "/api/v1/health"
```

---

### 2.2 GitHub Actions å·¥ä½œæµ

#### .github/workflows/ci.yml

```yaml
name: CI

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]

jobs:
  lint:
    name: Lint
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Run lint
        run: pnpm lint

  typecheck:
    name: Type Check
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Generate Prisma Client
        run: pnpm db:generate

      - name: Type check
        run: pnpm --filter @readmigo/backend exec tsc --noEmit

  test:
    name: Test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Generate Prisma Client
        run: pnpm db:generate

      - name: Run tests
        run: pnpm test

  build:
    name: Build
    runs-on: ubuntu-latest
    needs: [lint, typecheck, test]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Generate Prisma Client
        run: pnpm db:generate

      - name: Build
        run: pnpm build
```

#### .github/workflows/deploy-staging.yml

```yaml
name: Deploy to Staging

on:
  push:
    branches: [main]
    paths:
      - 'apps/backend/**'
      - 'packages/**'
      - 'Dockerfile'
      - 'fly.staging.toml'
      - '.github/workflows/deploy-staging.yml'
  workflow_dispatch:

env:
  FLY_API_TOKEN: ${{ secrets.FLY_STAGING_TOKEN }}

jobs:
  ci:
    name: CI Checks
    uses: ./.github/workflows/ci.yml

  deploy:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: ci
    environment: staging

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Fly CLI
        uses: superfly/flyctl-action/setup-flyctl@master

      - name: Deploy to Staging
        run: flyctl deploy --config fly.staging.toml --remote-only

      - name: Run Database Migrations
        run: |
          flyctl ssh console --app readmigo-staging -C "cd /app && npx prisma migrate deploy"

      - name: Health Check
        run: |
          sleep 30
          response=$(curl -s -o /dev/null -w "%{http_code}" https://staging-api.readmigo.app/api/v1/health)
          if [ "$response" != "200" ]; then
            echo "Health check failed with status: $response"
            exit 1
          fi
          echo "Health check passed!"

      - name: Notify Success
        if: success()
        run: |
          echo "âœ… Staging deployment successful!"
          echo "URL: https://staging-api.readmigo.app"

      - name: Notify Failure
        if: failure()
        run: |
          echo "âŒ Staging deployment failed!"
```

#### .github/workflows/deploy-production.yml

```yaml
name: Deploy to Production

on:
  workflow_dispatch:
    inputs:
      confirm:
        description: 'Type "deploy" to confirm production deployment'
        required: true
      skip_backup:
        description: 'Skip database backup (not recommended)'
        type: boolean
        default: false

env:
  FLY_API_TOKEN: ${{ secrets.FLY_PRODUCTION_TOKEN }}

jobs:
  validate:
    name: Validate Deployment
    runs-on: ubuntu-latest
    steps:
      - name: Validate Confirmation
        if: github.event.inputs.confirm != 'deploy'
        run: |
          echo "âŒ Deployment not confirmed. Please type 'deploy' to confirm."
          exit 1

      - name: Check Staging Health
        run: |
          response=$(curl -s -o /dev/null -w "%{http_code}" https://staging-api.readmigo.app/api/v1/health)
          if [ "$response" != "200" ]; then
            echo "âŒ Staging is not healthy. Please fix staging before deploying to production."
            exit 1
          fi
          echo "âœ… Staging health check passed"

  backup:
    name: Backup Database
    runs-on: ubuntu-latest
    needs: validate
    if: github.event.inputs.skip_backup != 'true'
    steps:
      - name: Create Neon Backup Branch
        run: |
          curl -X POST "https://console.neon.tech/api/v2/projects/${{ secrets.NEON_PROD_PROJECT_ID }}/branches" \
            -H "Authorization: Bearer ${{ secrets.NEON_API_KEY }}" \
            -H "Content-Type: application/json" \
            -d '{
              "branch": {
                "name": "backup-${{ github.run_id }}-${{ github.run_number }}"
              }
            }'
          echo "âœ… Database backup created"

  deploy:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [validate, backup]
    if: always() && needs.validate.result == 'success' && (needs.backup.result == 'success' || needs.backup.result == 'skipped')
    environment: production  # éœ€è¦æ‰‹åŠ¨å®¡æ‰¹

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Fly CLI
        uses: superfly/flyctl-action/setup-flyctl@master

      - name: Deploy to Production
        run: flyctl deploy --config fly.production.toml --remote-only

      - name: Run Database Migrations
        run: |
          flyctl ssh console --app readmigo-api -C "cd /app && npx prisma migrate deploy"

      - name: Health Check
        run: |
          sleep 60
          for i in {1..5}; do
            response=$(curl -s -o /dev/null -w "%{http_code}" https://api.readmigo.app/api/v1/health)
            if [ "$response" == "200" ]; then
              echo "âœ… Health check passed on attempt $i"
              exit 0
            fi
            echo "Health check attempt $i failed with status: $response"
            sleep 10
          done
          echo "âŒ Health check failed after 5 attempts"
          exit 1

      - name: Notify Success
        if: success()
        run: |
          echo "âœ… Production deployment successful!"
          echo "URL: https://api.readmigo.app"
          echo "Commit: ${{ github.sha }}"

  rollback-instructions:
    name: Rollback Instructions
    runs-on: ubuntu-latest
    needs: deploy
    if: failure()
    steps:
      - name: Print Rollback Instructions
        run: |
          echo "âŒ Production deployment failed!"
          echo ""
          echo "To rollback, run:"
          echo "  flyctl releases rollback --app readmigo-api"
          echo ""
          echo "To restore database (if needed):"
          echo "  1. Go to Neon Console"
          echo "  2. Find branch: backup-${{ github.run_id }}-${{ github.run_number }}"
          echo "  3. Restore from that branch"
```

#### .github/workflows/deploy-debugging.yml

```yaml
name: Deploy to Debugging

on:
  push:
    branches: [debugging]
    paths:
      - 'apps/backend/**'
      - 'packages/**'
      - 'Dockerfile'
      - 'fly.debugging.toml'
  workflow_dispatch:

env:
  FLY_API_TOKEN: ${{ secrets.FLY_DEBUGGING_TOKEN }}

jobs:
  deploy:
    name: Deploy to Debugging
    runs-on: ubuntu-latest
    environment: debugging

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Fly CLI
        uses: superfly/flyctl-action/setup-flyctl@master

      - name: Deploy to Debugging
        run: flyctl deploy --config fly.debugging.toml --remote-only

      - name: Run Database Migrations
        run: |
          flyctl ssh console --app readmigo-debug -C "cd /app && npx prisma migrate deploy"

      - name: Health Check
        run: |
          sleep 30
          response=$(curl -s -o /dev/null -w "%{http_code}" https://debug-api.readmigo.app/api/v1/health)
          if [ "$response" != "200" ]; then
            echo "Health check failed with status: $response"
            exit 1
          fi
          echo "âœ… Debugging deployment successful!"
```

#### .github/workflows/db-sync.yml

```yaml
name: Database Sync

on:
  schedule:
    # Staging: æ¯æ—¥å‡Œæ™¨ 3 ç‚¹ (UTC+8)
    - cron: '0 19 * * *'  # 19:00 UTC = 03:00 CST
  workflow_dispatch:
    inputs:
      target:
        description: 'Target environment'
        required: true
        type: choice
        options:
          - staging
          - debugging
      mode:
        description: 'Sync mode'
        required: true
        type: choice
        options:
          - full
          - content-only

jobs:
  sync-staging:
    name: Sync to Staging
    runs-on: ubuntu-latest
    if: github.event.schedule == '0 19 * * *' || github.event.inputs.target == 'staging'

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Run Database Sync
        run: |
          pnpm db:sync --from=production --to=staging --mode=${{ github.event.inputs.mode || 'full' }}
        env:
          DATABASE_URL_PRODUCTION: ${{ secrets.DATABASE_URL_PRODUCTION }}
          DATABASE_URL_STAGING: ${{ secrets.DATABASE_URL_STAGING }}
          ANONYMIZATION_SALT: ${{ secrets.ANONYMIZATION_SALT }}

  sync-debugging:
    name: Sync to Debugging
    runs-on: ubuntu-latest
    if: github.event.inputs.target == 'debugging'

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Run Database Sync
        run: |
          pnpm db:sync --from=production --to=debugging --mode=${{ github.event.inputs.mode || 'full' }}
        env:
          DATABASE_URL_PRODUCTION: ${{ secrets.DATABASE_URL_PRODUCTION }}
          DATABASE_URL_DEBUGGING: ${{ secrets.DATABASE_URL_DEBUGGING }}
          ANONYMIZATION_SALT: ${{ secrets.ANONYMIZATION_SALT }}
```

---

### 2.3 æ•°æ®åŒæ­¥è„šæœ¬

#### scripts/db-sync/anonymization-rules.ts

```typescript
import { faker } from '@faker-js/faker';
import { createHash } from 'crypto';

export interface AnonymizationRule {
  table: string;
  columns?: Record<string, AnonymizationStrategy>;
  exclude?: boolean;
}

type AnonymizationStrategy =
  | { type: 'hash'; salt?: string }
  | { type: 'fake'; generator: () => string }
  | { type: 'constant'; value: string }
  | { type: 'null' }
  | { type: 'preserve' };

export const anonymizationRules: AnonymizationRule[] = [
  // ç”¨æˆ·è¡¨ - æ ¸å¿ƒæ•æ„Ÿæ•°æ®åŒ¿ååŒ–
  {
    table: 'users',
    columns: {
      id: { type: 'preserve' },
      email: { type: 'hash' },
      name: { type: 'fake', generator: () => faker.person.fullName() },
      apple_user_id: { type: 'hash' },
      google_user_id: { type: 'hash' },
      avatar_url: { type: 'constant', value: 'https://assets.readmigo.app/defaults/avatar.png' },
      created_at: { type: 'preserve' },
      updated_at: { type: 'preserve' },
    },
  },

  // å®Œå…¨æ’é™¤çš„æ•æ„Ÿè¡¨
  { table: 'subscriptions', exclude: true },
  { table: 'subscription_transactions', exclude: true },
  { table: 'refresh_tokens', exclude: true },
  { table: 'audit_logs', exclude: true },
  { table: 'user_devices', exclude: true },

  // å†…å®¹è¡¨ - å®Œæ•´ä¿ç•™
  { table: 'books', columns: { '*': { type: 'preserve' } } },
  { table: 'authors', columns: { '*': { type: 'preserve' } } },
  { table: 'categories', columns: { '*': { type: 'preserve' } } },
  { table: 'book_categories', columns: { '*': { type: 'preserve' } } },
  { table: 'quotes', columns: { '*': { type: 'preserve' } } },
  { table: 'book_lists', columns: { '*': { type: 'preserve' } } },
  { table: 'book_list_items', columns: { '*': { type: 'preserve' } } },
  { table: 'postcards', columns: { '*': { type: 'preserve' } } },
  { table: 'postcard_templates', columns: { '*': { type: 'preserve' } } },
  { table: 'app_versions', columns: { '*': { type: 'preserve' } } },
  { table: 'feature_flags', columns: { '*': { type: 'preserve' } } },

  // ç”¨æˆ·æ´»åŠ¨æ•°æ® - ä¿ç•™ç»“æ„ï¼Œå…³è”åŒ¿åç”¨æˆ·
  { table: 'reading_sessions', columns: { '*': { type: 'preserve' } } },
  { table: 'user_vocabulary', columns: { '*': { type: 'preserve' } } },
  { table: 'user_badges', columns: { '*': { type: 'preserve' } } },

  // AI ç¼“å­˜ - ä¿ç•™ä»¥èŠ‚çœæˆæœ¬
  { table: 'ai_cache', columns: { '*': { type: 'preserve' } } },
];

export function hashValue(value: string, salt?: string): string {
  const data = salt ? `${salt}:${value}` : value;
  return createHash('sha256').update(data).digest('hex').substring(0, 16);
}

export function anonymizeEmail(email: string, salt?: string): string {
  const hash = hashValue(email, salt);
  return `user_${hash}@anonymized.local`;
}
```

#### scripts/db-sync/sync-manager.ts

```typescript
import { execSync } from 'child_process';
import * as fs from 'fs';
import * as path from 'path';
import { anonymizationRules, anonymizeEmail, hashValue } from './anonymization-rules';

type Environment = 'production' | 'staging' | 'debugging' | 'local';
type SyncMode = 'full' | 'content-only';

interface SyncOptions {
  source: Environment;
  target: Environment;
  mode: SyncMode;
  dryRun?: boolean;
  verbose?: boolean;
}

export class DatabaseSyncManager {
  private sourceUrl: string;
  private targetUrl: string;
  private tempDir: string;

  constructor(private options: SyncOptions) {
    this.sourceUrl = this.getConnectionUrl(options.source);
    this.targetUrl = this.getConnectionUrl(options.target);
    this.tempDir = path.join('/tmp', `db-sync-${Date.now()}`);
  }

  private getConnectionUrl(env: Environment): string {
    const envVar = `DATABASE_URL_${env.toUpperCase()}`;
    const url = process.env[envVar];
    if (!url) {
      throw new Error(`Environment variable ${envVar} is not set`);
    }
    return url;
  }

  async sync(): Promise<void> {
    console.log(`\nğŸ”„ Starting sync: ${this.options.source} â†’ ${this.options.target}`);
    console.log(`   Mode: ${this.options.mode}`);
    console.log(`   Dry run: ${this.options.dryRun ? 'Yes' : 'No'}\n`);

    fs.mkdirSync(this.tempDir, { recursive: true });

    try {
      // Step 1: å¯¼å‡ºæºæ•°æ®
      console.log('ğŸ“¤ Step 1: Exporting source database...');
      await this.exportDatabase();

      // Step 2: åŒ¿ååŒ–å¤„ç†
      console.log('ğŸ” Step 2: Applying anonymization...');
      await this.anonymizeData();

      // Step 3: å¯¼å…¥åˆ°ç›®æ ‡
      if (!this.options.dryRun) {
        console.log('ğŸ“¥ Step 3: Importing to target database...');
        await this.importDatabase();
      } else {
        console.log('ğŸ“¥ Step 3: Skipped (dry run)');
      }

      // Step 4: éªŒè¯
      console.log('âœ… Step 4: Verifying sync...');
      await this.verifySyncResult();

      console.log('\nâœ¨ Sync completed successfully!\n');
    } finally {
      this.cleanup();
    }
  }

  private async exportDatabase(): Promise<void> {
    const excludeTables = anonymizationRules
      .filter((r) => r.exclude)
      .map((r) => `--exclude-table-data=${r.table}`)
      .join(' ');

    const contentOnlyTables =
      this.options.mode === 'content-only'
        ? anonymizationRules
            .filter((r) => !r.exclude && r.table !== 'users')
            .filter((r) =>
              ['books', 'authors', 'categories', 'quotes', 'book_lists'].includes(r.table),
            )
            .map((r) => `--table=${r.table}`)
            .join(' ')
        : '';

    const cmd = `pg_dump "${this.sourceUrl}" \
      --format=custom \
      --no-owner \
      --no-acl \
      ${excludeTables} \
      ${contentOnlyTables} \
      --file="${this.tempDir}/dump.sql"`;

    if (this.options.verbose) {
      console.log(`   Command: ${cmd}`);
    }

    execSync(cmd, { stdio: this.options.verbose ? 'inherit' : 'pipe' });
    console.log('   âœ“ Export completed');
  }

  private async anonymizeData(): Promise<void> {
    const anonymizeSql = this.generateAnonymizationSql();
    const sqlPath = path.join(this.tempDir, 'anonymize.sql');
    fs.writeFileSync(sqlPath, anonymizeSql);

    console.log('   âœ“ Anonymization SQL generated');

    if (this.options.verbose) {
      console.log('   SQL Preview:');
      console.log(anonymizeSql.substring(0, 500) + '...');
    }
  }

  private generateAnonymizationSql(): string {
    const salt = process.env.ANONYMIZATION_SALT || 'default-salt';
    const statements: string[] = [
      '-- Anonymization Script',
      '-- Generated at: ' + new Date().toISOString(),
      '',
    ];

    // Users è¡¨åŒ¿ååŒ–
    statements.push(`
-- Anonymize users table
UPDATE users SET
  email = 'user_' || LEFT(MD5(email || '${salt}'), 12) || '@anonymized.local',
  name = 'User ' || LEFT(MD5(name || '${salt}'), 8),
  apple_user_id = CASE WHEN apple_user_id IS NOT NULL THEN LEFT(MD5(apple_user_id || '${salt}'), 32) ELSE NULL END,
  google_user_id = CASE WHEN google_user_id IS NOT NULL THEN LEFT(MD5(google_user_id || '${salt}'), 32) ELSE NULL END,
  avatar_url = 'https://assets.readmigo.app/defaults/avatar.png';
`);

    return statements.join('\n');
  }

  private async importDatabase(): Promise<void> {
    // å…ˆæ¢å¤æ•°æ®
    const restoreCmd = `pg_restore \
      --dbname="${this.targetUrl}" \
      --clean \
      --if-exists \
      --no-owner \
      --no-acl \
      "${this.tempDir}/dump.sql"`;

    try {
      execSync(restoreCmd, { stdio: this.options.verbose ? 'inherit' : 'pipe' });
    } catch (error) {
      // pg_restore å¯èƒ½ä¼šæœ‰è­¦å‘Šï¼Œä¸ä¸€å®šæ˜¯é”™è¯¯
      console.log('   âš ï¸  pg_restore completed with warnings');
    }

    // æ‰§è¡ŒåŒ¿ååŒ–
    const anonymizeCmd = `psql "${this.targetUrl}" -f "${this.tempDir}/anonymize.sql"`;
    execSync(anonymizeCmd, { stdio: this.options.verbose ? 'inherit' : 'pipe' });

    console.log('   âœ“ Import and anonymization completed');
  }

  private async verifySyncResult(): Promise<void> {
    // éªŒè¯ç”¨æˆ·è¡¨å·²åŒ¿ååŒ–
    const checkCmd = `psql "${this.targetUrl}" -t -c "SELECT COUNT(*) FROM users WHERE email NOT LIKE '%@anonymized.local'"`;

    try {
      const result = execSync(checkCmd, { encoding: 'utf-8' }).trim();
      const nonAnonymizedCount = parseInt(result, 10);

      if (nonAnonymizedCount > 0) {
        throw new Error(`Found ${nonAnonymizedCount} non-anonymized user records!`);
      }

      console.log('   âœ“ Anonymization verified: All user emails are anonymized');
    } catch (error) {
      if (this.options.mode === 'content-only') {
        console.log('   â„¹ï¸  Skipped user verification (content-only mode)');
      } else {
        throw error;
      }
    }
  }

  private cleanup(): void {
    try {
      fs.rmSync(this.tempDir, { recursive: true, force: true });
      console.log('   âœ“ Temporary files cleaned up');
    } catch {
      console.log('   âš ï¸  Failed to clean up temporary files');
    }
  }
}
```

#### scripts/db-sync/run-sync.ts

```typescript
import { DatabaseSyncManager } from './sync-manager';

async function main() {
  const args = process.argv.slice(2);

  // è§£æå‘½ä»¤è¡Œå‚æ•°
  const getArg = (name: string): string | undefined => {
    const arg = args.find((a) => a.startsWith(`--${name}=`));
    return arg?.split('=')[1];
  };

  const hasFlag = (name: string): boolean => {
    return args.includes(`--${name}`);
  };

  const source = getArg('from') as 'production' | undefined;
  const target = getArg('to') as 'staging' | 'debugging' | 'local' | undefined;
  const mode = (getArg('mode') || 'full') as 'full' | 'content-only';
  const dryRun = hasFlag('dry-run');
  const verbose = hasFlag('verbose');

  if (!source || !target) {
    console.error('Usage: pnpm db:sync --from=production --to=staging [--mode=full|content-only] [--dry-run] [--verbose]');
    process.exit(1);
  }

  if (source !== 'production') {
    console.error('Error: Source must be "production"');
    process.exit(1);
  }

  if (!['staging', 'debugging', 'local'].includes(target)) {
    console.error('Error: Target must be "staging", "debugging", or "local"');
    process.exit(1);
  }

  const manager = new DatabaseSyncManager({
    source,
    target,
    mode,
    dryRun,
    verbose,
  });

  try {
    await manager.sync();
  } catch (error) {
    console.error('âŒ Sync failed:', error);
    process.exit(1);
  }
}

main();
```

---

### 2.4 Package.json è„šæœ¬æ›´æ–°

#### æ ¹ç›®å½• package.json æ·»åŠ 

```json
{
  "scripts": {
    "db:sync": "tsx scripts/db-sync/run-sync.ts",
    "db:sync:content": "tsx scripts/db-sync/run-sync.ts --mode=content-only",
    "dev:debugging": "pnpm --filter @readmigo/backend dev:debugging"
  }
}
```

#### apps/backend/package.json æ·»åŠ 

```json
{
  "scripts": {
    "dev:debugging": "ENVIRONMENT=debugging nest start --watch",
    "start:debugging": "ENVIRONMENT=debugging nest start"
  }
}
```

---

## 3. GitHub Secrets é…ç½®

éœ€è¦åœ¨ GitHub ä»“åº“è®¾ç½®ä¸­é…ç½®ä»¥ä¸‹ Secrets:

| Secret åç§° | ç”¨é€” | ç¯å¢ƒ |
|------------|------|------|
| `FLY_DEBUGGING_TOKEN` | Fly.io Debugging éƒ¨ç½² Token | debugging |
| `FLY_STAGING_TOKEN` | Fly.io Staging éƒ¨ç½² Token | staging |
| `FLY_PRODUCTION_TOKEN` | Fly.io Production éƒ¨ç½² Token | production |
| `DATABASE_URL_PRODUCTION` | Production æ•°æ®åº“è¿æ¥ä¸² | - |
| `DATABASE_URL_STAGING` | Staging æ•°æ®åº“è¿æ¥ä¸² | - |
| `DATABASE_URL_DEBUGGING` | Debugging æ•°æ®åº“è¿æ¥ä¸² | - |
| `NEON_PROD_PROJECT_ID` | Neon Production é¡¹ç›® ID | production |
| `NEON_API_KEY` | Neon API Key | production |
| `ANONYMIZATION_SALT` | æ•°æ®åŒ¿ååŒ–ç›å€¼ | - |

---

## 4. GitHub Environments é…ç½®

éœ€è¦åˆ›å»ºä»¥ä¸‹ Environments:

| Environment | ä¿æŠ¤è§„åˆ™ |
|-------------|---------|
| debugging | æ—  |
| staging | æ—  |
| production | Required reviewers (è‡³å°‘1äººå®¡æ‰¹) |

---

## 5. å®æ–½é¡ºåº

1. **åˆ›å»º Fly.io é…ç½®æ–‡ä»¶** (fly.debugging.toml, fly.staging.toml, fly.production.toml)
2. **æ›´æ–° GitHub Actions** (ci.yml, deploy-staging.yml, deploy-production.yml, deploy-debugging.yml)
3. **é…ç½® GitHub Secrets å’Œ Environments**
4. **åˆ›å»ºæ•°æ®åŒæ­¥è„šæœ¬**
5. **æ›´æ–° package.json è„šæœ¬**
6. **æµ‹è¯•éƒ¨ç½²æµç¨‹**

---

è¯· review ä»¥ä¸Šé…ç½®æ–‡ä»¶è¯¦ç»†è®¡åˆ’ã€‚
